{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T08:03:47.836634Z","iopub.execute_input":"2023-05-06T08:03:47.837006Z","iopub.status.idle":"2023-05-06T08:03:47.846128Z","shell.execute_reply.started":"2023-05-06T08:03:47.836977Z","shell.execute_reply":"2023-05-06T08:03:47.844894Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#load in datasets\nimport pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:48.075365Z","iopub.execute_input":"2023-05-06T08:03:48.075756Z","iopub.status.idle":"2023-05-06T08:03:48.145006Z","shell.execute_reply.started":"2023-05-06T08:03:48.075723Z","shell.execute_reply":"2023-05-06T08:03:48.143911Z"},"trusted":true},"execution_count":217,"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0         2   2008        WD         Normal     208500  \n1         5   2007        WD         Normal     181500  \n2         9   2008        WD         Normal     223500  \n3         2   2006        WD        Abnorml     140000  \n4        12   2008        WD         Normal     250000  \n...     ...    ...       ...            ...        ...  \n1455      8   2007        WD         Normal     175000  \n1456      2   2010        WD         Normal     210000  \n1457      5   2010        WD         Normal     266500  \n1458      4   2010        WD         Normal     142125  \n1459      6   2008        WD         Normal     147500  \n\n[1460 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#drop rows where the missing values are greater than half of the length of the df, in the train&test df\nto_drop = list(train_df.columns[train_df.isna().sum()>(len(train_df)/2)])\ntrain_df.drop(to_drop, axis=1, inplace=True)\ntest_df.drop(to_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:48.270785Z","iopub.execute_input":"2023-05-06T08:03:48.271680Z","iopub.status.idle":"2023-05-06T08:03:48.294948Z","shell.execute_reply.started":"2023-05-06T08:03:48.271641Z","shell.execute_reply":"2023-05-06T08:03:48.293614Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"to_drop = list(test_df.columns[test_df.isna().sum()>(len(test_df)/2)])\ntrain_df.drop(to_drop, axis=1, inplace=True)\ntest_df.drop(to_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:48.474175Z","iopub.execute_input":"2023-05-06T08:03:48.474548Z","iopub.status.idle":"2023-05-06T08:03:48.496686Z","shell.execute_reply.started":"2023-05-06T08:03:48.474512Z","shell.execute_reply":"2023-05-06T08:03:48.495178Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"#fill every missing values where the type is int or float\nnum_cols_train = train_df.select_dtypes(include=['int', 'float']).columns.tolist()\nnum_cols_test = test_df.select_dtypes(include=['int', 'float']).columns.tolist() #doesnt has the saleprice column","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:48.643703Z","iopub.execute_input":"2023-05-06T08:03:48.644104Z","iopub.status.idle":"2023-05-06T08:03:48.651308Z","shell.execute_reply.started":"2023-05-06T08:03:48.644047Z","shell.execute_reply":"2023-05-06T08:03:48.649960Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"train_df[num_cols_test] = train_df[num_cols_test].fillna(train_df[num_cols_test].mean())\ntest_df[num_cols_test] = test_df[num_cols_test].fillna(test_df[num_cols_test].mean())","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:48.818984Z","iopub.execute_input":"2023-05-06T08:03:48.819821Z","iopub.status.idle":"2023-05-06T08:03:48.874668Z","shell.execute_reply.started":"2023-05-06T08:03:48.819781Z","shell.execute_reply":"2023-05-06T08:03:48.873406Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"#check how many columns have missing data\nlen(list(train_df.columns[train_df.isna().sum()>0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.002958Z","iopub.execute_input":"2023-05-06T08:03:49.004259Z","iopub.status.idle":"2023-05-06T08:03:49.025913Z","shell.execute_reply.started":"2023-05-06T08:03:49.004210Z","shell.execute_reply":"2023-05-06T08:03:49.024576Z"},"trusted":true},"execution_count":222,"outputs":[{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}]},{"cell_type":"code","source":"#try and concat the two dfs and then replace all categorical columns with numbers\n#because if you dont concat the two together, you get a different number of columns in each df\nfinal = pd.concat([train_df, test_df], axis=0)\nobj_cols_fin = final.select_dtypes(include=['object']).columns.tolist()\nfinal = pd.get_dummies(final, columns=obj_cols_fin)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.169645Z","iopub.execute_input":"2023-05-06T08:03:49.170349Z","iopub.status.idle":"2023-05-06T08:03:49.232896Z","shell.execute_reply.started":"2023-05-06T08:03:49.170307Z","shell.execute_reply":"2023-05-06T08:03:49.231727Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"final.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.333605Z","iopub.execute_input":"2023-05-06T08:03:49.334009Z","iopub.status.idle":"2023-05-06T08:03:49.341000Z","shell.execute_reply.started":"2023-05-06T08:03:49.333976Z","shell.execute_reply":"2023-05-06T08:03:49.339744Z"},"trusted":true},"execution_count":224,"outputs":[{"execution_count":224,"output_type":"execute_result","data":{"text/plain":"(2919, 272)"},"metadata":{}}]},{"cell_type":"code","source":"#remove duplicate columns\nfinal = final.loc[:,~final.columns.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.514767Z","iopub.execute_input":"2023-05-06T08:03:49.515262Z","iopub.status.idle":"2023-05-06T08:03:49.524142Z","shell.execute_reply.started":"2023-05-06T08:03:49.515230Z","shell.execute_reply":"2023-05-06T08:03:49.522983Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"#get all the categorical data and turn into numbers\nobj_cols_train = train_df.select_dtypes(include=['object']).columns.tolist()\ntrain_df = pd.get_dummies(train_df, columns=obj_cols_train)\nobj_cols_test = test_df.select_dtypes(include=['object']).columns.tolist()\ntest_df = pd.get_dummies(test_df, columns=obj_cols_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.663980Z","iopub.execute_input":"2023-05-06T08:03:49.664375Z","iopub.status.idle":"2023-05-06T08:03:49.742554Z","shell.execute_reply.started":"2023-05-06T08:03:49.664346Z","shell.execute_reply":"2023-05-06T08:03:49.741524Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:49.854530Z","iopub.execute_input":"2023-05-06T08:03:49.854945Z","iopub.status.idle":"2023-05-06T08:03:49.860163Z","shell.execute_reply.started":"2023-05-06T08:03:49.854912Z","shell.execute_reply":"2023-05-06T08:03:49.859114Z"},"trusted":true},"execution_count":227,"outputs":[{"name":"stdout","text":"(1460, 272)\n(1459, 255)\n","output_type":"stream"}]},{"cell_type":"code","source":"#test if the shape of the \"final\" df is correct\nfinal.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.008094Z","iopub.execute_input":"2023-05-06T08:03:50.008485Z","iopub.status.idle":"2023-05-06T08:03:50.016006Z","shell.execute_reply.started":"2023-05-06T08:03:50.008455Z","shell.execute_reply":"2023-05-06T08:03:50.014736Z"},"trusted":true},"execution_count":228,"outputs":[{"execution_count":228,"output_type":"execute_result","data":{"text/plain":"(2919, 272)"},"metadata":{}}]},{"cell_type":"code","source":"from copy import deepcopy\n\n#divide final df into train sub\ntrain_sub = deepcopy(final.iloc[:1460,:])\ntrain_sub","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.254653Z","iopub.execute_input":"2023-05-06T08:03:50.255028Z","iopub.status.idle":"2023-05-06T08:03:50.284596Z","shell.execute_reply.started":"2023-05-06T08:03:50.255000Z","shell.execute_reply":"2023-05-06T08:03:50.283513Z"},"trusted":true},"execution_count":229,"outputs":[{"execution_count":229,"output_type":"execute_result","data":{"text/plain":"        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n0        1          60         65.0     8450            7            5   \n1        2          20         80.0     9600            6            8   \n2        3          60         68.0    11250            7            5   \n3        4          70         60.0     9550            7            5   \n4        5          60         84.0    14260            8            5   \n...    ...         ...          ...      ...          ...          ...   \n1455  1456          60         62.0     7917            6            5   \n1456  1457          20         85.0    13175            6            6   \n1457  1458          70         66.0     9042            7            9   \n1458  1459          20         68.0     9717            5            6   \n1459  1460          20         75.0     9937            5            6   \n\n      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n0          2003          2003       196.0       706.0  ...               0   \n1          1976          1976         0.0       978.0  ...               0   \n2          2001          2002       162.0       486.0  ...               0   \n3          1915          1970         0.0       216.0  ...               0   \n4          2000          2000       350.0       655.0  ...               0   \n...         ...           ...         ...         ...  ...             ...   \n1455       1999          2000         0.0         0.0  ...               0   \n1456       1978          1988       119.0       790.0  ...               0   \n1457       1941          2006         0.0       275.0  ...               0   \n1458       1950          1996         0.0        49.0  ...               0   \n1459       1965          1965         0.0       830.0  ...               0   \n\n      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n0                0             0            1                      0   \n1                0             0            1                      0   \n2                0             0            1                      0   \n3                0             0            1                      1   \n4                0             0            1                      0   \n...            ...           ...          ...                    ...   \n1455             0             0            1                      0   \n1456             0             0            1                      0   \n1457             0             0            1                      0   \n1458             0             0            1                      0   \n1459             0             0            1                      0   \n\n      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n0                         0                     0                     0   \n1                         0                     0                     0   \n2                         0                     0                     0   \n3                         0                     0                     0   \n4                         0                     0                     0   \n...                     ...                   ...                   ...   \n1455                      0                     0                     0   \n1456                      0                     0                     0   \n1457                      0                     0                     0   \n1458                      0                     0                     0   \n1459                      0                     0                     0   \n\n      SaleCondition_Normal  SaleCondition_Partial  \n0                        1                      0  \n1                        1                      0  \n2                        1                      0  \n3                        0                      0  \n4                        1                      0  \n...                    ...                    ...  \n1455                     1                      0  \n1456                     1                      0  \n1457                     1                      0  \n1458                     1                      0  \n1459                     1                      0  \n\n[1460 rows x 272 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>SaleType_ConLw</th>\n      <th>SaleType_New</th>\n      <th>SaleType_Oth</th>\n      <th>SaleType_WD</th>\n      <th>SaleCondition_Abnorml</th>\n      <th>SaleCondition_AdjLand</th>\n      <th>SaleCondition_Alloca</th>\n      <th>SaleCondition_Family</th>\n      <th>SaleCondition_Normal</th>\n      <th>SaleCondition_Partial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 272 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#fill misssing values\n#train_sub = train_sub.fillna(train_sub.mean())\n#set input X and y\nX_train, y_train = train_sub.drop([\"SalePrice\"],axis=1).to_numpy(), train_sub[\"SalePrice\"].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.344460Z","iopub.execute_input":"2023-05-06T08:03:50.344888Z","iopub.status.idle":"2023-05-06T08:03:50.352670Z","shell.execute_reply.started":"2023-05-06T08:03:50.344853Z","shell.execute_reply":"2023-05-06T08:03:50.351365Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.583132Z","iopub.execute_input":"2023-05-06T08:03:50.583576Z","iopub.status.idle":"2023-05-06T08:03:50.592524Z","shell.execute_reply.started":"2023-05-06T08:03:50.583540Z","shell.execute_reply":"2023-05-06T08:03:50.591121Z"},"trusted":true},"execution_count":231,"outputs":[{"execution_count":231,"output_type":"execute_result","data":{"text/plain":"(1460, 271)"},"metadata":{}}]},{"cell_type":"code","source":"#get LR model\nfrom sklearn.linear_model import LinearRegression\n#train model\nlr = LinearRegression().fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.659436Z","iopub.execute_input":"2023-05-06T08:03:50.659961Z","iopub.status.idle":"2023-05-06T08:03:50.782769Z","shell.execute_reply.started":"2023-05-06T08:03:50.659927Z","shell.execute_reply":"2023-05-06T08:03:50.781276Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"#train_sub[\"predictions\"] = lr.predict(X_train)\n#train_sub","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:50.791809Z","iopub.execute_input":"2023-05-06T08:03:50.797355Z","iopub.status.idle":"2023-05-06T08:03:50.808397Z","shell.execute_reply.started":"2023-05-06T08:03:50.797269Z","shell.execute_reply":"2023-05-06T08:03:50.806849Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"#get the other half of the final df to be the test sub df\ntest_sub = deepcopy(final.iloc[1460:,:].drop([\"SalePrice\"],axis=1))\ntest_sub","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:51.128315Z","iopub.execute_input":"2023-05-06T08:03:51.128727Z","iopub.status.idle":"2023-05-06T08:03:51.159726Z","shell.execute_reply.started":"2023-05-06T08:03:51.128695Z","shell.execute_reply":"2023-05-06T08:03:51.158217Z"},"trusted":true},"execution_count":234,"outputs":[{"execution_count":234,"output_type":"execute_result","data":{"text/plain":"        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n0     1461          20         80.0    11622            5            6   \n1     1462          20         81.0    14267            6            6   \n2     1463          60         74.0    13830            5            5   \n3     1464          60         78.0     9978            6            6   \n4     1465         120         43.0     5005            8            5   \n...    ...         ...          ...      ...          ...          ...   \n1454  2915         160         21.0     1936            4            7   \n1455  2916         160         21.0     1894            4            5   \n1456  2917          20        160.0    20000            5            7   \n1457  2918          85         62.0    10441            5            5   \n1458  2919          60         74.0     9627            7            5   \n\n      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n0          1961          1961         0.0       468.0  ...               0   \n1          1958          1958       108.0       923.0  ...               0   \n2          1997          1998         0.0       791.0  ...               0   \n3          1998          1998        20.0       602.0  ...               0   \n4          1992          1992         0.0       263.0  ...               0   \n...         ...           ...         ...         ...  ...             ...   \n1454       1970          1970         0.0         0.0  ...               0   \n1455       1970          1970         0.0       252.0  ...               0   \n1456       1960          1996         0.0      1224.0  ...               0   \n1457       1992          1992         0.0       337.0  ...               0   \n1458       1993          1994        94.0       758.0  ...               0   \n\n      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n0                0             0            1                      0   \n1                0             0            1                      0   \n2                0             0            1                      0   \n3                0             0            1                      0   \n4                0             0            1                      0   \n...            ...           ...          ...                    ...   \n1454             0             0            1                      0   \n1455             0             0            1                      1   \n1456             0             0            1                      1   \n1457             0             0            1                      0   \n1458             0             0            1                      0   \n\n      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n0                         0                     0                     0   \n1                         0                     0                     0   \n2                         0                     0                     0   \n3                         0                     0                     0   \n4                         0                     0                     0   \n...                     ...                   ...                   ...   \n1454                      0                     0                     0   \n1455                      0                     0                     0   \n1456                      0                     0                     0   \n1457                      0                     0                     0   \n1458                      0                     0                     0   \n\n      SaleCondition_Normal  SaleCondition_Partial  \n0                        1                      0  \n1                        1                      0  \n2                        1                      0  \n3                        1                      0  \n4                        1                      0  \n...                    ...                    ...  \n1454                     1                      0  \n1455                     0                      0  \n1456                     0                      0  \n1457                     1                      0  \n1458                     1                      0  \n\n[1459 rows x 271 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>SaleType_ConLw</th>\n      <th>SaleType_New</th>\n      <th>SaleType_Oth</th>\n      <th>SaleType_WD</th>\n      <th>SaleCondition_Abnorml</th>\n      <th>SaleCondition_AdjLand</th>\n      <th>SaleCondition_Alloca</th>\n      <th>SaleCondition_Family</th>\n      <th>SaleCondition_Normal</th>\n      <th>SaleCondition_Partial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>20</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1961</td>\n      <td>1961</td>\n      <td>0.0</td>\n      <td>468.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>20</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1958</td>\n      <td>1958</td>\n      <td>108.0</td>\n      <td>923.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>60</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1997</td>\n      <td>1998</td>\n      <td>0.0</td>\n      <td>791.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>60</td>\n      <td>78.0</td>\n      <td>9978</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1998</td>\n      <td>1998</td>\n      <td>20.0</td>\n      <td>602.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>120</td>\n      <td>43.0</td>\n      <td>5005</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1992</td>\n      <td>1992</td>\n      <td>0.0</td>\n      <td>263.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>160</td>\n      <td>21.0</td>\n      <td>1936</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1970</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>160</td>\n      <td>21.0</td>\n      <td>1894</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1970</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>252.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>20</td>\n      <td>160.0</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1960</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>1224.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>85</td>\n      <td>62.0</td>\n      <td>10441</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1992</td>\n      <td>1992</td>\n      <td>0.0</td>\n      <td>337.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>60</td>\n      <td>74.0</td>\n      <td>9627</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1993</td>\n      <td>1994</td>\n      <td>94.0</td>\n      <td>758.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 271 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#convert to numpy\nX_test = test_sub.to_numpy()\nX_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:51.241324Z","iopub.execute_input":"2023-05-06T08:03:51.241787Z","iopub.status.idle":"2023-05-06T08:03:51.253210Z","shell.execute_reply.started":"2023-05-06T08:03:51.241751Z","shell.execute_reply":"2023-05-06T08:03:51.251614Z"},"trusted":true},"execution_count":235,"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"(1459, 271)"},"metadata":{}}]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:51.829928Z","iopub.execute_input":"2023-05-06T08:03:51.830554Z","iopub.status.idle":"2023-05-06T08:03:51.836338Z","shell.execute_reply.started":"2023-05-06T08:03:51.830522Z","shell.execute_reply":"2023-05-06T08:03:51.835134Z"},"trusted":true},"execution_count":236,"outputs":[{"execution_count":236,"output_type":"execute_result","data":{"text/plain":"(1460, 271)"},"metadata":{}}]},{"cell_type":"code","source":"#test_df[\"SalePrice\"] = lr.predict(X_test)\n#test_df","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:51.984573Z","iopub.execute_input":"2023-05-06T08:03:51.984970Z","iopub.status.idle":"2023-05-06T08:03:51.989876Z","shell.execute_reply.started":"2023-05-06T08:03:51.984942Z","shell.execute_reply":"2023-05-06T08:03:51.988722Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"#test_df[[\"Id\",\"SalePrice\"]].to_csv(\"prediction1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:52.151129Z","iopub.execute_input":"2023-05-06T08:03:52.151534Z","iopub.status.idle":"2023-05-06T08:03:52.156536Z","shell.execute_reply.started":"2023-05-06T08:03:52.151503Z","shell.execute_reply":"2023-05-06T08:03:52.155309Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"import xgboost\nregressor = xgboost.XGBRegressor(n_estimators=500)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:52.419447Z","iopub.execute_input":"2023-05-06T08:03:52.419876Z","iopub.status.idle":"2023-05-06T08:03:52.424811Z","shell.execute_reply.started":"2023-05-06T08:03:52.419844Z","shell.execute_reply":"2023-05-06T08:03:52.423581Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"#define parameter grid for hyperparameter tuning\nbooster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1]\n\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\n\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:52.620311Z","iopub.execute_input":"2023-05-06T08:03:52.620701Z","iopub.status.idle":"2023-05-06T08:03:52.626976Z","shell.execute_reply.started":"2023-05-06T08:03:52.620669Z","shell.execute_reply":"2023-05-06T08:03:52.626171Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"# Set up the random search with 4-fold cross validation\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:31:43.345158Z","iopub.execute_input":"2023-05-06T07:31:43.345550Z","iopub.status.idle":"2023-05-06T07:31:43.351518Z","shell.execute_reply.started":"2023-05-06T07:31:43.345519Z","shell.execute_reply":"2023-05-06T07:31:43.350342Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"#print(X_test.shape)\n#print(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:31:59.605720Z","iopub.execute_input":"2023-05-06T07:31:59.606738Z","iopub.status.idle":"2023-05-06T07:31:59.612049Z","shell.execute_reply.started":"2023-05-06T07:31:59.606685Z","shell.execute_reply":"2023-05-06T07:31:59.611207Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"(1459, 271)\n(1460, 271)\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the random_cv \nrandom_cv.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:32:07.999355Z","iopub.execute_input":"2023-05-06T07:32:07.999720Z","iopub.status.idle":"2023-05-06T07:48:02.997452Z","shell.execute_reply.started":"2023-05-06T07:32:07.999693Z","shell.execute_reply":"2023-05-06T07:48:02.996151Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 50 candidates, totalling 250 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[07:32:09] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=1500;, score=(train=-13607.662, test=-16532.695) total time=   6.4s\n[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-2084.147, test=-15491.192) total time=  17.9s\n[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-2105.945, test=-16387.096) total time=  18.1s\n[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=900;, score=(train=-4.455, test=-14660.554) total time= 1.1min\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-3113.506, test=-16141.913) total time=  17.5s\n[07:34:13] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=100;, score=(train=-14638.937, test=-18346.483) total time=   0.4s\n[07:34:13] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=100;, score=(train=-13846.352, test=-19721.270) total time=   0.4s\n[07:34:14] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=100;, score=(train=-13686.439, test=-20611.006) total time=   0.4s\n[07:34:14] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=100;, score=(train=-14374.890, test=-17142.616) total time=   0.4s\n[07:34:15] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=100;, score=(train=-13986.709, test=-19837.709) total time=   0.4s\n[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-2309.355, test=-14792.239) total time=  17.8s\n[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-2196.083, test=-13502.570) total time=  17.5s\n[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-30.526, test=-17782.215) total time=  23.9s\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=900;, score=(train=-6464.627, test=-16402.840) total time=  10.5s\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=900;, score=(train=-6202.610, test=-16193.445) total time=  11.1s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=900;, score=(train=-0.044, test=-15181.053) total time= 1.1min\n[07:36:43] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13212.666, test=-19182.348) total time=   3.9s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=1500;, score=(train=-503.489, test=-16575.571) total time=  24.8s\n[07:37:12] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13721.479, test=-17782.133) total time=   2.1s\n[07:37:14] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13217.748, test=-18753.032) total time=   2.1s\n[07:37:16] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-12904.917, test=-19796.784) total time=   2.1s\n[07:37:19] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13651.299, test=-16432.247) total time=   2.1s\n[07:37:21] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13223.273, test=-19120.484) total time=   2.1s\n[07:37:23] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=500;, score=(train=-14221.910, test=-17920.777) total time=   2.1s\n[07:37:25] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=500;, score=(train=-13530.491, test=-19300.633) total time=   2.1s\n[07:37:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=500;, score=(train=-13411.144, test=-20347.261) total time=   2.1s\n[07:37:29] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=500;, score=(train=-14120.772, test=-16531.669) total time=   2.1s\n[07:37:31] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=500;, score=(train=-13669.044, test=-19371.609) total time=   2.1s\n[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=1, n_estimators=900;, score=(train=-0.073, test=-17635.778) total time= 1.1min\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, min_child_weight=4, n_estimators=900;, score=(train=-9035.499, test=-15369.902) total time=  10.6s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, min_child_weight=4, n_estimators=900;, score=(train=-9178.368, test=-13782.036) total time=  10.5s\n[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-735.626, test=-17085.983) total time=  15.4s\n[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-841.902, test=-18365.548) total time=  14.7s\n[07:39:32] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13677.854, test=-17768.351) total time=   3.7s\n[07:39:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[07:32:09] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=1500;, score=(train=-13216.340, test=-18719.234) total time=   6.5s\n[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-1898.662, test=-16026.403) total time=  18.4s\n[07:32:34] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13239.206, test=-18793.234) total time=   2.1s\n[07:32:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13761.449, test=-16309.164) total time=   2.1s\n[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=900;, score=(train=-1.886, test=-16129.881) total time= 1.1min\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-3173.736, test=-15752.759) total time=  18.2s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-3222.970, test=-13764.880) total time=  17.4s\n[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-2319.719, test=-17549.968) total time=  18.1s\n[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-2206.201, test=-18073.462) total time=  17.6s\n[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-4.882, test=-14263.706) total time=  24.8s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=900;, score=(train=-6438.674, test=-15322.413) total time=  11.0s\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=900;, score=(train=-0.053, test=-16621.720) total time= 1.1min\n[07:36:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13677.851, test=-17768.347) total time=   3.9s\n[07:36:40] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-12861.815, test=-19753.940) total time=   3.9s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=1500;, score=(train=-503.110, test=-15306.142) total time=  25.4s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=1500;, score=(train=-479.179, test=-14352.176) total time=  24.2s\n[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=1, n_estimators=900;, score=(train=-0.058, test=-18462.961) total time= 1.1min\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, min_child_weight=4, n_estimators=900;, score=(train=-8776.936, test=-16853.322) total time=  10.5s\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, min_child_weight=4, n_estimators=900;, score=(train=-8598.260, test=-16852.564) total time=  10.5s\n[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-768.538, test=-16993.593) total time=  15.1s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=100;, score=(train=-1337.040, test=-15908.544) total time=   4.9s\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=100;, score=(train=-1332.713, test=-16522.149) total time=   4.8s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=100;, score=(train=-1253.673, test=-15283.162) total time=   4.8s\n[07:39:33] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13203.941, test=-18725.251) total time=   3.7s\n[07:39:37] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13212.665, test=-19182.348) total time=   3.7s\n[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-0.046, test=-18206.801) total time=  36.7s\n[07:40:17] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-13917.804, test=-19870.236) total time=   0.5s\n[07:40:18] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14426.146, test=-17086.047) total time=   0.5s\n[07:40:18] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=900;, score=(train=-13677.851, test=-17768.347) total time=   3.9s\n[07:40:22] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=900;, score=(train=-12861.815, test=-19753.940) total time=   3.8s\n[07:40:26] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-15442.704, test=-18308.234) total time=   0.5s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14513.340, test=-20685.642) total time=   0.4s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=100;, score=(train=-15442.701, test=-18308.228) total time=   0.5s\n[07:40:28] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=100;, score=(train=-15235.238, test=-17312.351) total time=   0.4s\n[07:40:28] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=900;, score=(train=-13309.544, test=-18888.464) total time=   3.8s\n[07:40:32] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[07:32:09] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=1500;, score=(train=-13670.654, test=-17781.445) total time=   6.5s\n[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-1833.195, test=-16519.325) total time=  18.1s\n[07:32:34] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13860.670, test=-17834.018) total time=   2.1s\n[07:32:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13030.657, test=-19949.162) total time=   2.1s\n[07:32:38] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-13352.128, test=-19103.072) total time=   2.1s\n[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=900;, score=(train=-19.845, test=-17686.310) total time= 1.1min\n[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=900;, score=(train=-29.764, test=-17004.356) total time= 1.0min\n[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-3.824, test=-17277.015) total time=  24.6s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=900;, score=(train=-6547.902, test=-14920.684) total time=  10.5s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=900;, score=(train=-6699.558, test=-13745.324) total time=  10.8s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=900;, score=(train=-0.054, test=-17907.434) total time= 1.1min\n[07:36:37] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13203.941, test=-18725.251) total time=   4.0s\n[07:36:41] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13615.529, test=-16402.159) total time=   3.9s\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=1500;, score=(train=-429.548, test=-16575.684) total time=  25.2s\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=1500;, score=(train=-517.184, test=-19509.404) total time=  24.0s\n[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=1, n_estimators=900;, score=(train=-0.078, test=-16925.866) total time= 1.1min\n[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=1, n_estimators=900;, score=(train=-0.062, test=-18748.963) total time= 1.1min\n[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-0.029, test=-14793.469) total time=  36.6s\n[07:40:23] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=900;, score=(train=-13212.666, test=-19182.348) total time=   3.6s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-15235.239, test=-17312.355) total time=   0.4s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=100;, score=(train=-14652.955, test=-20441.236) total time=   0.4s\n[07:40:28] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=100;, score=(train=-14713.498, test=-19820.945) total time=   0.4s\n[07:40:28] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=900;, score=(train=-13125.937, test=-20035.060) total time=   3.7s\n[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=-4396.758, test=-15732.074) total time=   2.6s\n[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=-4238.407, test=-16237.017) total time=   2.6s\n[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=-4421.625, test=-17432.034) total time=   2.6s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-0.038, test=-17738.428) total time= 1.8min\n[07:42:29] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=2, n_estimators=500;, score=(train=-14221.912, test=-17920.782) total time=   2.1s\n[07:42:31] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=2, n_estimators=500;, score=(train=-13530.490, test=-19300.633) total time=   2.1s\n[07:42:33] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=2, n_estimators=500;, score=(train=-14120.772, test=-16531.664) total time=   2.1s\n[07:42:35] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=100;, score=(train=-14902.822, test=-18471.075) total time=   0.4s\n[07:42:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=100;, score=(train=-14102.065, test=-19999.560) total time=   0.4s\n[07:42:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=100;, score=(train=-13956.798, test=-20582.095) total time=   0.4s\n[07:42:37] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=100;, score=(train=-14635.283, test=-17054.189) total time=   0.5s\n[07:42:37] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[07:32:09] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=1500;, score=(train=-12833.248, test=-19780.030) total time=   6.4s\n[07:32:16] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.2, max_depth=15, min_child_weight=1, n_estimators=1500;, score=(train=-13227.937, test=-19434.782) total time=   6.5s\n[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-2112.896, test=-13276.436) total time=  17.7s\n[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=900;, score=(train=-4.194, test=-17077.049) total time= 1.1min\n[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-3121.088, test=-16654.883) total time=  17.8s\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-3152.599, test=-17445.578) total time=  17.6s\n[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-2111.877, test=-17023.236) total time=  18.0s\n[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-19.202, test=-15943.344) total time=  24.6s\n[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=4, n_estimators=500;, score=(train=-70.454, test=-17008.562) total time=  23.7s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=900;, score=(train=-0.043, test=-16234.550) total time= 1.1min\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=900;, score=(train=-0.042, test=-17157.682) total time= 1.1min\n[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=15, min_child_weight=1, n_estimators=900;, score=(train=-0.065, test=-15459.765) total time= 1.1min\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, min_child_weight=4, n_estimators=900;, score=(train=-8933.192, test=-16474.385) total time=  10.6s\n[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-813.431, test=-15779.614) total time=  14.7s\n[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-846.578, test=-14718.181) total time=  14.9s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=100;, score=(train=-1586.915, test=-17804.381) total time=   4.9s\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=100;, score=(train=-1735.209, test=-17101.822) total time=   4.8s\n[07:39:36] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-12861.816, test=-19753.943) total time=   3.9s\n[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-0.030, test=-17000.236) total time=  37.2s\n[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-0.036, test=-17611.519) total time=  36.6s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-0.032, test=-16418.799) total time= 1.8min\n[CV 2/5] END base_score=0.75, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=500;, score=(train=-6986.292, test=-16704.001) total time=   5.9s\n[CV 5/5] END base_score=0.75, booster=gbtree, learning_rate=0.15, max_depth=2, min_child_weight=3, n_estimators=500;, score=(train=-6827.858, test=-17447.373) total time=   6.0s\n[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=1500;, score=(train=-0.026, test=-18206.856) total time= 1.8min\n[07:44:44] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-13216.340, test=-18719.236) total time=   6.4s\n[07:44:50] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, min_child_weight=3, n_estimators=1500;, score=(train=-13607.660, test=-16532.698) total time=   6.3s\n[07:44:57] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=10, min_child_weight=2, n_estimators=1500;, score=(train=-13757.713, test=-17851.782) total time=   6.3s\n[07:45:03] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=10, min_child_weight=2, n_estimators=1500;, score=(train=-12932.739, test=-19756.221) total time=   6.5s\n[07:45:10] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=10, min_child_weight=2, n_estimators=1500;, score=(train=-13283.373, test=-19123.183) total time=   6.1s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=900;, score=(train=-874.219, test=-14892.461) total time=  14.6s\n[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=900;, score=(train=-865.233, test=-14057.021) total time=  15.0s\n[07:45:45] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=1, n_estimators=1100;, score=(train=-13670.775, test=-17768.520) total time=   4.5s\n[07:45:50] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=1, n_estimators=1100;, score=(train=-13208.252, test=-18724.590) total time=   4.6s\n[07:45:54] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=1, n_estimators=1100;, score=(train=-12852.670, test=-19759.097) total time=   4.5s\n[07:45:59] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=1, n_estimators=1100;, score=(train=-13608.955, test=-16436.187) total time=   4.6s\n[07:46:04] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-13746.325, test=-17799.173) total time=   2.1s\n[07:46:06] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-13249.373, test=-19052.630) total time=   2.3s\n[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=900;, score=(train=-13615.528, test=-16402.157) total time=   3.9s\n[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-0.027, test=-16068.608) total time=  37.0s\n[07:40:17] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14734.065, test=-18438.234) total time=   0.6s\n[07:40:18] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-13765.595, test=-20530.511) total time=   0.5s\n[07:40:18] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14046.646, test=-19794.448) total time=   0.5s\n[07:40:19] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=900;, score=(train=-13203.941, test=-18725.251) total time=   3.9s\n[07:40:23] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=900;, score=(train=-13615.529, test=-16402.159) total time=   3.8s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14652.954, test=-20441.234) total time=   0.5s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=2, min_child_weight=2, n_estimators=100;, score=(train=-14713.499, test=-19820.942) total time=   0.4s\n[07:40:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=100;, score=(train=-14513.344, test=-20685.647) total time=   0.5s\n[07:40:28] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=900;, score=(train=-13940.477, test=-17889.879) total time=   3.8s\n[07:40:32] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=900;, score=(train=-13848.928, test=-16288.092) total time=   3.9s\n[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=-4049.480, test=-16272.691) total time=   2.5s\n[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-0.047, test=-17385.890) total time= 1.8min\n[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-0.031, test=-17903.793) total time= 1.8min\n[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=1500;, score=(train=-0.029, test=-14793.416) total time= 1.9min\n[07:46:04] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-13195.120, test=-18731.620) total time=   2.1s\n[07:46:06] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=15, min_child_weight=3, n_estimators=500;, score=(train=-13663.958, test=-16322.671) total time=   2.6s\n[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, min_child_weight=4, n_estimators=500;, score=(train=-350.623, test=-16852.430) total time=  12.6s\n[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100;, score=(train=-13691.139, test=-16917.646) total time=   1.2s\n[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100;, score=(train=-13402.146, test=-17972.493) total time=   1.2s\n[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100;, score=(train=-13666.080, test=-16899.125) total time=   1.2s\n[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100;, score=(train=-14033.590, test=-16284.023) total time=   1.2s\n[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100;, score=(train=-13575.323, test=-18014.582) total time=   1.2s\n[07:46:27] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-13677.852, test=-17768.350) total time=   3.7s\n[07:46:31] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=3, min_child_weight=2, n_estimators=900;, score=(train=-12861.817, test=-19753.941) total time=   3.8s\n[07:46:35] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=-13190.398, test=-18714.758) total time=   4.9s\n[07:46:40] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-13757.713, test=-17851.785) total time=   6.6s\n[07:46:46] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=15, min_child_weight=2, n_estimators=1500;, score=(train=-13283.371, test=-19123.184) total time=   6.2s\n[CV 4/5] END base_score=0.75, booster=gbtree, learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=-61.389, test=-13984.435) total time=  28.4s\n[07:47:21] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=10, min_child_weight=2, n_estimators=1100;, score=(train=-12862.053, test=-19713.646) total time=   4.7s\n[07:47:26] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=-13677.854, test=-17768.353) total time=   3.8s\n[07:47:29] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=-13615.526, test=-16402.153) total time=   3.9s\n[07:47:33] WARNING: ../src/learner.cc:767: \nParameters: { \"max_depth\", \"min_child_weight\" } are not used.\n\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=5,\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          callbacks=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          early_stopping_rounds=None,\n                                          enable_categorical=False,\n                                          eval_metric=None, feature_types=None,\n                                          gamma=None, gpu_id=None,\n                                          grow_policy=None,\n                                          importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=...\n                                          predictor=None, random_state=None, ...),\n                   n_iter=50, n_jobs=4,\n                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n                                        'booster': ['gbtree', 'gblinear'],\n                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n                                        'max_depth': [2, 3, 5, 10, 15],\n                                        'min_child_weight': [1, 2, 3, 4],\n                                        'n_estimators': [100, 500, 900, 1100,\n                                                         1500]},\n                   random_state=42, return_train_score=True,\n                   scoring='neg_mean_absolute_error', verbose=5)","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          callbacks=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          early_stopping_rounds=None,\n                                          enable_categorical=False,\n                                          eval_metric=None, feature_types=None,\n                                          gamma=None, gpu_id=None,\n                                          grow_policy=None,\n                                          importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=...\n                                          predictor=None, random_state=None, ...),\n                   n_iter=50, n_jobs=4,\n                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n                                                         1500]},\n                   random_state=42, return_train_score=True,\n                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          callbacks=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          early_stopping_rounds=None,\n                                          enable_categorical=False,\n                                          eval_metric=None, feature_types=None,\n                                          gamma=None, gpu_id=None,\n                                          grow_policy=None,\n                                          importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=...\n                                          predictor=None, random_state=None, ...),\n                   n_iter=50, n_jobs=4,\n                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n                                                         1500]},\n                   random_state=42, return_train_score=True,\n                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"#print out best parameters\nprint(\"Best hyperparameters:\", random_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:48:22.281050Z","iopub.execute_input":"2023-05-06T07:48:22.281687Z","iopub.status.idle":"2023-05-06T07:48:22.287485Z","shell.execute_reply.started":"2023-05-06T07:48:22.281644Z","shell.execute_reply":"2023-05-06T07:48:22.286349Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Best hyperparameters: {'n_estimators': 900, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.1, 'booster': 'gbtree', 'base_score': 0.25}\n","output_type":"stream"}]},{"cell_type":"code","source":"#get best estimator and fit it to the data\nbest = random_cv.best_estimator_\nbest.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:03:58.050897Z","iopub.execute_input":"2023-05-06T08:03:58.051310Z","iopub.status.idle":"2023-05-06T08:04:01.633160Z","shell.execute_reply.started":"2023-05-06T08:03:58.051278Z","shell.execute_reply":"2023-05-06T08:04:01.631716Z"},"trusted":true},"execution_count":241,"outputs":[{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)","text/html":"<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"#test_df[\"SalePrice\"] = best.predict(X_test)\n#test_df[[\"Id\",\"SalePrice\"]].to_csv(\"prediction1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:01.635418Z","iopub.execute_input":"2023-05-06T08:04:01.636234Z","iopub.status.idle":"2023-05-06T08:04:01.641840Z","shell.execute_reply.started":"2023-05-06T08:04:01.636194Z","shell.execute_reply":"2023-05-06T08:04:01.639656Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"#debug cell: check if the shape is correct\nprint(X_test.shape)\nprint(X_train.shape)\nimportances = best.feature_importances_\nprint(importances.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:01.643791Z","iopub.execute_input":"2023-05-06T08:04:01.644751Z","iopub.status.idle":"2023-05-06T08:04:01.661684Z","shell.execute_reply.started":"2023-05-06T08:04:01.644706Z","shell.execute_reply":"2023-05-06T08:04:01.660282Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"(1459, 271)\n(1460, 271)\n(271,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the feature importances and check for high correlation\n#if a high correlation is there, drop one column\nimport numpy as np\n\nimportances = best.feature_importances_\n\ndef drop_corr_cols(X, importances, threshold=0.9):\n    cols_to_drop = []\n    for i in range(X.shape[1]):\n        for j in range(i+1, X.shape[1]):\n            corr = np.corrcoef(X[:, i], X[:, j])[0, 1]\n            if abs(corr) >= threshold:\n                if importances[i] >= importances[j]:\n                    cols_to_drop.append(j)\n                    #print(\"Dropped feature\", j, \"because it was highly correlated with feature\", i)\n                else:\n                    cols_to_drop.append(i)\n                    #print(\"Dropped feature\", i, \"because it was highly correlated with feature\", j)\n    X = np.delete(X, cols_to_drop, axis=1)\n    return X, cols_to_drop\n\nX_train, cols_to_drop = drop_corr_cols(X_train, importances)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:03.923544Z","iopub.execute_input":"2023-05-06T08:04:03.924164Z","iopub.status.idle":"2023-05-06T08:04:07.908901Z","shell.execute_reply.started":"2023-05-06T08:04:03.924122Z","shell.execute_reply":"2023-05-06T08:04:07.907616Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"#debug cell for shape\nprint(X_test.shape)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:16.744148Z","iopub.execute_input":"2023-05-06T08:04:16.744527Z","iopub.status.idle":"2023-05-06T08:04:16.750239Z","shell.execute_reply.started":"2023-05-06T08:04:16.744499Z","shell.execute_reply":"2023-05-06T08:04:16.749143Z"},"trusted":true},"execution_count":245,"outputs":[{"name":"stdout","text":"(1459, 271)\n(1460, 259)\n","output_type":"stream"}]},{"cell_type":"code","source":"#delete the cols that have high correlation in the test set as well\nX_test = np.delete(X_test,cols_to_drop, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:30.515660Z","iopub.execute_input":"2023-05-06T08:04:30.516049Z","iopub.status.idle":"2023-05-06T08:04:30.521590Z","shell.execute_reply.started":"2023-05-06T08:04:30.516021Z","shell.execute_reply":"2023-05-06T08:04:30.520152Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"#fit the best regressor on the new data without the highly correlated cols\nbest = random_cv.best_estimator_\nbest.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:35.460813Z","iopub.execute_input":"2023-05-06T08:04:35.461229Z","iopub.status.idle":"2023-05-06T08:04:39.131935Z","shell.execute_reply.started":"2023-05-06T08:04:35.461194Z","shell.execute_reply":"2023-05-06T08:04:39.130761Z"},"trusted":true},"execution_count":249,"outputs":[{"execution_count":249,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)","text/html":"<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=2, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"#predict prices and make new column\ntest_df[\"SalePrice\"] = best.predict(X_test)\ntest_df[[\"Id\",\"SalePrice\"]].to_csv(\"prediction1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:04:41.337566Z","iopub.execute_input":"2023-05-06T08:04:41.337960Z","iopub.status.idle":"2023-05-06T08:04:41.382267Z","shell.execute_reply.started":"2023-05-06T08:04:41.337927Z","shell.execute_reply":"2023-05-06T08:04:41.381354Z"},"trusted":true},"execution_count":250,"outputs":[]}]}